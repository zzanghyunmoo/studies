# 프로메테우스 생태계 개요

## 질문

### 1. 프로메테우스 생태계의 주요 구성 요소는 무엇인가?

**답변:**

프로메테우스 생태계는 여러 독립적이면서도 통합된 구성 요소로 이루어져 있습니다.

#### 핵심 구성 요소:

**1. 프로메테우스 서버 (Prometheus Server)**
   - 시계열 데이터베이스 (TSDB)
   - 메트릭 수집 엔진 (Scraper)
   - PromQL 쿼리 엔진
   - 기본 웹 UI 및 API

**2. 익스포터 (Exporters)**
   - 애플리케이션/시스템 메트릭을 프로메테우스 포맷으로 노출
   - 예: node_exporter, blackbox_exporter, mysqld_exporter 등

**3. 클라이언트 라이브러리 (Client Libraries)**
   - 애플리케이션 코드에 계측(instrumentation)을 추가
   - Go, Java, Python, Ruby 등 다양한 언어 지원

**4. 푸시게이트웨이 (Pushgateway)**
   - 단기 실행 작업(short-lived jobs)의 메트릭 수집
   - 배치 작업, 크론 잡 등에서 사용

**5. 알림매니저 (Alertmanager)**
   - 알림 라우팅, 그룹핑, 중복 제거
   - 통합(Slack, PagerDuty, Email 등)
   - Silencing 및 Inhibition 기능

**6. 서비스 디스커버리 (Service Discovery)**
   - 동적 타겟 발견
   - Kubernetes, Consul, EC2 등 통합

#### 주변 생태계:

- **Grafana**: 고급 시각화 및 대시보드
- **Thanos/Cortex**: 장기 저장 및 고가용성

**시니어 SRE 관점**: 이 구성 요소들은 느슨하게 결합되어 있어, 필요에 따라 선택적으로 사용할 수 있습니다. 이는 프로메테우스의 강점이자 유연성의 핵심입니다.

---

### 2. 프로메테우스 배포에 필수적인 구성 요소는 무엇인가? 그리고 어떤 구성 요소가 선택 사항인가?

**답변:**

#### 필수 구성 요소:

**1. 프로메테우스 서버 (Prometheus Server)**
   - 모든 것의 중심
   - 이것 없이는 프로메테우스를 사용할 수 없음

**2. 메트릭 소스 (최소 하나)**
   - 인스트루먼테이션된 애플리케이션 또는
   - 익스포터 (예: node_exporter)
   - 메트릭을 수집할 대상이 필요

#### 선택적 구성 요소:

**1. 알림매니저 (Alertmanager)**
   - 알림이 필요 없다면 불필요
   - 프로메테우스 자체에서 알림 규칙 평가는 하지만, 전송은 알림매니저가 담당
   - **실무에서는 거의 필수**

**2. 푸시게이트웨이 (Pushgateway)**
   - 장기 실행 서비스만 모니터링한다면 불필요
   - 배치 작업이 있을 때만 필요
   - **안티패턴으로 남용되기 쉬우므로 주의**

**3. 익스포터 (Exporters)**
   - 애플리케이션이 직접 메트릭을 노출한다면 불필요
   - 하지만 대부분의 경우 시스템 메트릭을 위해 node_exporter는 필요

**4. 서비스 디스커버리 통합**
   - 정적 설정(static_configs)으로도 충분할 수 있음
   - 동적 환경(Kubernetes, 클라우드)에서는 거의 필수

**5. Grafana**
   - 프로메테우스 자체 UI로도 기본 쿼리 가능
   - 하지만 대시보드와 고급 시각화를 위해서는 거의 필수

**6. 장기 저장 솔루션 (Thanos/Cortex)**
   - 기본 프로메테우스는 로컬 스토리지만 사용
   - 장기 보관이나 고가용성이 필요할 때만

#### 시니어 SRE 관점:

**최소 실행 가능 배포 (MVP):**
```
프로메테우스 서버 + 메트릭 소스 (애플리케이션 또는 익스포터)
```

**프로덕션 권장 배포:**
```
프로메테우스 서버 + Alertmanager + node_exporter + Grafana + 서비스 디스커버리
```

선택은 **운영 성숙도**와 **요구사항**에 따라 달라집니다. 작게 시작해서 필요에 따라 확장하는 것이 좋습니다.

---

### 3. 아웃오브프로세스 익스포터가 필요한 이유는 무엇인가?

**답변:**

아웃오브프로세스(Out-of-Process) 익스포터는 별도의 프로세스로 실행되는 익스포터를 의미합니다.

#### 주요 이유:

**1. 소스 코드 접근 불가 또는 수정 불가능**
   - 서드파티 소프트웨어 (MySQL, PostgreSQL, Redis 등)
   - 레거시 시스템
   - 벤더 제공 소프트웨어
   - **예**: MySQL 소스 코드를 수정할 수 없으므로 mysqld_exporter 사용

**2. 언어/런타임 제약**
   - 프로메테우스 클라이언트 라이브러리가 없는 언어
   - 계측이 어려운 환경 (COBOL, 어셈블리 등)
   - 프로메테우스 포맷으로 메트릭 노출이 불가능한 애플리케이션

**3. 관심사의 분리 (Separation of Concerns)**
   - 애플리케이션 로직과 모니터링 로직 분리
   - 메트릭 수집 실패가 애플리케이션에 영향 없음
   - 독립적인 재시작, 업그레이드 가능

**4. 재사용성 및 표준화**
   - 동일한 익스포터를 여러 인스턴스에서 사용
   - 커뮤니티 표준 익스포터 활용
   - 조직 전체에서 일관된 메트릭 수집

**5. 보안 및 권한 분리**
   - 익스포터가 제한된 권한으로 실행
   - 애플리케이션과 다른 보안 경계
   - 민감한 정보 필터링 가능

**6. 특수한 수집 방식**
   - **Blackbox Exporter**: 외부 관점의 테스트 (HTTP, DNS, ICMP 등)
   - **SNMP Exporter**: SNMP 프로토콜을 통한 네트워크 장비 모니터링
   - **JMX Exporter**: Java JMX 메트릭 수집

#### 실제 예시:

**시나리오 1: MySQL 모니터링**
- MySQL은 자체적으로 프로메테우스 메트릭을 노출하지 않음
- mysqld_exporter가 MySQL에 연결하여 상태를 쿼리
- 프로메테우스 포맷으로 변환하여 노출

**시나리오 2: 레거시 애플리케이션**
- 10년 된 Java 애플리케이션, 소스 수정 불가
- JMX로 메트릭 노출 중
- jmx_exporter를 사이드카로 배포
- 애플리케이션 변경 없이 프로메테우스 메트릭 수집

**시나리오 3: 네트워크 장비**
- 스위치/라우터는 SNMP만 지원
- snmp_exporter가 SNMP를 프로메테우스 포맷으로 변환

#### 시니어 SRE 관점의 트레이드오프:

**장점:**
- 유연성: 어떤 시스템도 모니터링 가능
- 독립성: 애플리케이션과 분리된 생명주기
- 안정성: 익스포터 문제가 앱에 영향 없음

**단점:**
- 추가 관리 포인트: 또 하나의 프로세스/서비스
- 지연 가능성: 추가 네트워크 홉
- 복잡도 증가: 더 많은 구성 요소

**결론**: 아웃오브프로세스 익스포터는 **불가피한 경우** 또는 **명확한 이점**이 있을 때 사용합니다. 가능하다면 애플리케이션에 직접 계측하는 것이 더 간단하고 효율적입니다.

---

### 4. HTTP GET 요청이 익스포터의 메트릭 엔드포인트에 도달하면 어떤 일이 발생하는가?

**답변:**

메트릭 엔드포인트에 대한 HTTP GET 요청 처리 과정을 단계별로 설명합니다.

#### 처리 과정:

**1. 요청 수신 (Request Reception)**
```
GET /metrics HTTP/1.1
Host: node-exporter:9100
User-Agent: Prometheus/2.x
```

**2. 메트릭 수집 시작 (Collection Triggered)**
   - **중요**: 대부분의 익스포터는 요청 시점에 메트릭을 수집합니다
   - 사전에 메트릭을 캐싱하지 않음 (일부 예외 있음)
   - **On-demand 방식**

**3. 데이터 소스 쿼리 (Data Source Query)**
   ```
   node_exporter 예시:
   - /proc/stat 파일 읽기 → CPU 메트릭
   - /proc/meminfo 읽기 → 메모리 메트릭
   - /sys/class/net 읽기 → 네트워크 메트릭
   
   mysqld_exporter 예시:
   - SHOW GLOBAL STATUS 쿼리 실행
   - SHOW GLOBAL VARIABLES 쿼리 실행
   - 테이블 크기 등 추가 쿼리
   ```

**4. 메트릭 변환 및 포맷팅 (Metric Transformation)**
   - 원시 데이터를 프로메테우스 메트릭 타입으로 변환
   - 메트릭 이름 표준화
   - 레이블 추가
   
   ```
   원시 데이터: 
   Bytes_sent: 123456789
   
   프로메테우스 포맷:
   mysql_global_status_bytes_sent{instance="mysql-1"} 123456789
   ```

**5. 텍스트 포맷 생성 (Text Format Generation)**
   ```
   # HELP node_cpu_seconds_total Seconds the CPUs spent in each mode.
   # TYPE node_cpu_seconds_total counter
   node_cpu_seconds_total{cpu="0",mode="idle"} 12345.67
   node_cpu_seconds_total{cpu="0",mode="system"} 234.56
   node_cpu_seconds_total{cpu="0",mode="user"} 789.12
   ```

**6. HTTP 응답 전송 (Response Transmission)**
   ```
   HTTP/1.1 200 OK
   Content-Type: text/plain; version=0.0.4; charset=utf-8
   Content-Length: XXXX
   
   [메트릭 데이터]
   ```

#### 중요한 특성들:

**1. 동기적 수집 (Synchronous Collection)**
   - 요청이 올 때마다 새롭게 수집
   - 항상 최신 데이터
   - 수집 시간만큼 응답 지연

**2. 타임아웃 고려 (Timeout Considerations)**
   - 프로메테우스 기본 스크랩 타임아웃: 10초
   - 익스포터는 이 시간 내에 응답해야 함
   - 느린 쿼리는 타임아웃 발생 가능

**3. 메트릭 생성 비용 (Cost of Metric Generation)**
   ```
   경량 익스포터 (node_exporter):
   - 파일 시스템 읽기: ~10-50ms
   
   중량 익스포터 (mysqld_exporter):
   - 데이터베이스 쿼리: 수백ms ~ 수초
   - 많은 테이블: 더 오래 걸림
   
   매우 무거운 작업:
   - 디스크 전체 스캔
   - 복잡한 집계 쿼리
   → 이런 경우 별도 수집 및 캐싱 필요
   ```

**4. 동시 요청 처리 (Concurrent Requests)**
   - 대부분의 익스포터는 동시 요청 처리 가능
   - 하지만 데이터 소스가 병목이 될 수 있음
   - 예: 동일 MySQL에 여러 쿼리 동시 실행

#### 시니어 SRE 관점의 주의사항:

**1. 메트릭 카디널리티 (Cardinality)**
```
잘못된 예:
http_requests_total{user_id="12345"}  # 수백만 개의 시계열!

올바른 예:
http_requests_total{status="200"}     # 제한된 시계열
```

**2. 수집 시간 최적화**
- 느린 쿼리는 별도 스레드에서 주기적으로 수집하고 캐싱
- 필요한 메트릭만 활성화
- 타임아웃 내에 응답 보장

**3. 에러 처리**
- 일부 메트릭 수집 실패 시에도 나머지는 노출
- 스크랩 성공/실패를 나타내는 메타 메트릭 제공
  ```
  up{job="node-exporter"} 1
  scrape_duration_seconds 0.045
  scrape_samples_scraped 200
  ```

**4. 보안 고려사항**
- 민감한 정보 노출 주의 (패스워드, 키 등)
- 인증/권한 설정 (기본적으로 익스포터는 인증 없음)
- 네트워크 격리 (방화벽, 서비스 메시 등)

**결론**: 메트릭 엔드포인트 요청은 단순해 보이지만, 실제로는 복잡한 데이터 수집, 변환, 포맷팅 과정을 거칩니다. 이 과정의 효율성이 전체 모니터링 시스템의 성능과 안정성에 직접적인 영향을 미칩니다.

---

### 5. 네트워크 파티션이 발생하면 알림 매니저 클러스터에서 트리거되는 알림은 어떻게 되는가?

**답변:**

알림매니저의 고가용성 설계와 네트워크 파티션 시 동작을 분석합니다.

#### 정상 상태의 알림매니저 클러스터:

**1. 가십 프로토콜 (Gossip Protocol)**
   - 알림매니저 인스턴스들은 가십 프로토콜로 통신
   - 각 인스턴스는 알림 상태를 공유
   - 알림 중복 제거 (Deduplication)
   - 그룹핑 및 억제(Inhibition) 정보 공유

**2. 중복 제거 메커니즘**
   ```
   시나리오:
   - 프로메테우스 A → 알림매니저 1에 알림 전송
   - 프로메테우스 B → 알림매니저 2에 동일 알림 전송
   
   결과:
   - 알림매니저들이 서로 통신하여 중복 감지
   - 한 번만 알림 전송
   ```

#### 네트워크 파티션 발생 시:

**상황 설정:**
```
알림매니저 클러스터: AM1, AM2, AM3
네트워크 파티션으로 분할:
- 파티션 A: AM1, AM2
- 파티션 B: AM3
```

**발생하는 일:**

**1. 중복 알림 발생 가능성 (Duplicate Alerts)**
   - 각 파티션이 독립적으로 동작
   - 동일한 알림이 여러 번 전송될 수 있음
   
   ```
   예시:
   - 프로메테우스가 AM1과 AM3 모두에 알림 전송
   - AM1과 AM3이 서로 통신 불가
   - 둘 다 알림을 Slack으로 전송
   - 결과: 중복 알림!
   ```

**2. 알림 상태 불일치 (State Divergence)**
   - 각 파티션이 자체적인 알림 상태 유지
   - Silencing이 한쪽 파티션에만 적용될 수 있음
   
   ```
   시나리오:
   - AM1에서 알림 Silence 설정
   - AM3은 이를 모름
   - AM3에서 계속 알림 발송
   ```

**3. 그룹핑 문제 (Grouping Issues)**
   - 알림 그룹핑이 파티션별로 다르게 동작
   - 원래 하나로 묶여야 할 알림이 별도로 전송될 수 있음

#### 알림매니저의 설계 철학:

**"Availability over Consistency" (가용성 우선)**

- **CAP 정리**: 알림매니저는 AP 시스템 (Availability + Partition Tolerance)
- **설계 결정**: 알림을 놓치는 것보다 중복 알림이 나음
- **트레이드오프**: 네트워크 파티션 시 중복을 허용

#### 파티션 복구 후:

**1. 재수렴 (Re-convergence)**
   - 가십 프로토콜이 다시 동작
   - 상태 정보가 점진적으로 동기화
   - 수 초 ~ 수 분 소요 (클러스터 크기에 따라)

**2. 상태 조정 (State Reconciliation)**
   - 알림 상태가 병합됨
   - Silence 정보가 전파됨
   - 중복 제거가 다시 정상화

#### 시니어 SRE 관점의 모범 사례:

**1. 프로메테우스 설정 최적화**
```yaml
alerting:
  alertmanagers:
  - static_configs:
    - targets:
      - alertmanager-1:9093
      - alertmanager-2:9093
      - alertmanager-3:9093
    # 모든 알림매니저에 전송
```

**2. 수신자(Receiver) 멱등성 보장**
- 알림 수신 시스템이 중복을 처리할 수 있도록 설계
- 예: PagerDuty는 dedup_key 사용

**3. 클러스터 토폴로지 고려**
- 여러 가용 영역(AZ)에 분산 배치
- 홀수 개의 인스턴스 (3, 5 등)
- 쿼럼 기반은 아니지만 베스트 프랙티스

**4. 알림매니저 자체 모니터링**
```promql
# 클러스터 멤버 수 감소 감지
alertmanager_cluster_members < 3

# 가십 메시지 실패 감지
rate(alertmanager_cluster_messages_received_total{msg_type="gossip"}[5m]) == 0
```

**5. 장기 파티션 대응**
- 알림매니저는 메모리 기반 (재시작 시 상태 손실)
- 장기 파티션 시 디스크에 일부 상태 저장
- 하지만 여전히 완전한 consistency 보장 안 함

#### 실전 권장사항:

**최소 3개 인스턴스**
```
단일 인스턴스: 고가용성 없음
2개 인스턴스: 파티션 시 둘 다 알림 전송
3개 인스턴스: 파티션 시에도 majority가 정상 동작할 가능성 높음
```

**중복 알림 수용**
- 온콜 엔지니어는 중복 알림을 이해하고 수용
- "한 번도 받지 못하는 것보다 두 번 받는 게 낫다"

**결론**: 네트워크 파티션 시 알림매니저는 **중복 알림**을 보낼 수 있습니다. 이는 의도된 설계 결정이며, 알림 누락보다 중복을 선택한 것입니다. 프로덕션 환경에서는 이를 이해하고, 수신 시스템에서 멱등성을 보장하거나 중복을 허용하는 프로세스를 구축해야 합니다.

---

### 6. 알림 매니저를 사용자 정의 API와 통합해야 한다는 것을 깨달았을 것이다. 가장 빠른 옵션은 무엇인가?

**답변:**

알림매니저를 커스텀 API와 통합하는 가장 빠른 방법은 **Webhook Receiver**입니다.

#### 가장 빠른 옵션: Webhook Receiver

**왜 Webhook이 가장 빠른가?**
- 알림매니저 내장 기능
- 추가 소프트웨어 설치 불필요
- 간단한 HTTP POST 처리만 구현하면 됨

#### 구현 방법:

**1. 알림매니저 설정 (alertmanager.yml)**
```yaml
route:
  receiver: 'custom-api'
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 1h

receivers:
- name: 'custom-api'
  webhook_configs:
  - url: 'https://my-custom-api.example.com/alerts'
    send_resolved: true
    http_config:
      bearer_token: 'my-secret-token'  # 선택사항
    max_alerts: 0  # 0 = 무제한
```

**2. 커스텀 API 엔드포인트 구현**

**Python Flask 예시:**
```python
from flask import Flask, request, jsonify
import json

app = Flask(__name__)

@app.route('/alerts', methods=['POST'])
def receive_alert():
    data = request.json
    
    # 알림 데이터 처리
    for alert in data.get('alerts', []):
        status = alert.get('status')  # firing or resolved
        labels = alert.get('labels', {})
        annotations = alert.get('annotations', {})
        
        # 커스텀 로직 처리
        process_alert(alert)
    
    return jsonify({'status': 'success'}), 200

def process_alert(alert):
    # 여기서 원하는 작업 수행
    # - 티켓 시스템에 이슈 생성
    # - 사내 챗봇에 알림
    # - 데이터베이스에 저장
    # - 외부 API 호출
    print(f"Alert: {alert}")

if __name__ == '__main__':
    app.run(host='0.0.0.0', port=5000)
```

**Go 예시 (프로덕션 레벨):**
```go
package main

import (
    "encoding/json"
    "log"
    "net/http"
)

type AlertManagerPayload struct {
    Alerts []Alert `json:"alerts"`
    Status string  `json:"status"`
}

type Alert struct {
    Status       string            `json:"status"`
    Labels       map[string]string `json:"labels"`
    Annotations  map[string]string `json:"annotations"`
    StartsAt     string            `json:"startsAt"`
    EndsAt       string            `json:"endsAt"`
}

func alertHandler(w http.ResponseWriter, r *http.Request) {
    if r.Method != http.MethodPost {
        http.Error(w, "Method not allowed", http.StatusMethodNotAllowed)
        return
    }

    var payload AlertManagerPayload
    if err := json.NewDecoder(r.Body).Decode(&payload); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }

    // 알림 처리
    for _, alert := range payload.Alerts {
        processAlert(alert)
    }

    w.WriteHeader(http.StatusOK)
    json.NewEncoder(w).Encode(map[string]string{"status": "success"})
}

func processAlert(alert Alert) {
    log.Printf("Received alert: %s - %s", 
        alert.Labels["alertname"], 
        alert.Status)
}

func main() {
    http.HandleFunc("/alerts", alertHandler)
    log.Println("Starting webhook receiver on :5000")
    log.Fatal(http.ListenAndServe(":5000", nil))
}
```

#### 페이로드 형식:

**알림매니저가 보내는 JSON 구조:**
```json
{
  "version": "4",
  "groupKey": "{}:{alertname=\"HighErrorRate\"}",
  "status": "firing",
  "receiver": "custom-api",
  "groupLabels": {
    "alertname": "HighErrorRate"
  },
  "commonLabels": {
    "alertname": "HighErrorRate",
    "severity": "critical",
    "service": "api"
  },
  "commonAnnotations": {
    "summary": "High error rate detected",
    "description": "Error rate is above 5% for 5 minutes"
  },
  "externalURL": "http://alertmanager:9093",
  "alerts": [
    {
      "status": "firing",
      "labels": {
        "alertname": "HighErrorRate",
        "severity": "critical",
        "service": "api",
        "instance": "api-1"
      },
      "annotations": {
        "summary": "High error rate detected",
        "description": "Error rate is above 5% for 5 minutes"
      },
      "startsAt": "2025-10-20T10:00:00.000Z",
      "endsAt": "0001-01-01T00:00:00Z",
      "generatorURL": "http://prometheus:9090/graph?..."
    }
  ]
}
```

#### 시니어 SRE 관점의 프로덕션 고려사항:

**1. 안정성 (Reliability)**
```python
import threading

@app.route('/alerts', methods=['POST'])
def receive_alert():
    try:
        data = request.json
        # 비동기 처리로 타임아웃 방지
        threading.Thread(
            target=process_alerts_async, 
            args=(data,)
        ).start()
        
        # 즉시 200 응답 반환
        return jsonify({'status': 'accepted'}), 200
    except Exception as e:
        log.error(f"Error: {e}")
        # 알림매니저가 재시도하도록 5xx 반환
        return jsonify({'error': str(e)}), 500
```

**2. 멱등성 (Idempotency)**
```python
# 동일한 알림을 여러 번 받을 수 있음
def process_alert(alert):
    alert_id = generate_alert_id(alert)
    
    if already_processed(alert_id):
        return  # 스킵
    
    # 처리
    create_ticket(alert)
    mark_as_processed(alert_id)
```

**3. 보안 (Security)**
```python
# Bearer token 검증
@app.route('/alerts', methods=['POST'])
def receive_alert():
    token = request.headers.get('Authorization')
    if not token or not validate_token(token):
        return jsonify({'error': 'Unauthorized'}), 401
    # 처리
```

**4. 모니터링**
```python
from prometheus_client import Counter

alerts_received = Counter(
    'webhook_alerts_received_total',
    'Total alerts received'
)
```

#### 빠른 시작 템플릿:

**최소한의 작동 예시 (5분 안에 구현):**
```python
from flask import Flask, request
import json

app = Flask(__name__)

@app.route('/alerts', methods=['POST'])
def alerts():
    print(json.dumps(request.json, indent=2))
    return '', 200

app.run(host='0.0.0.0', port=5000)
```

#### 결론:

**가장 빠른 옵션은 Webhook Receiver입니다.**

**구현 시간:**
- 프로토타입: 10-30분
- 프로덕션 수준: 반나절 ~ 1일

**이유:**
1. 내장 기능 (추가 설치 없음)
2. 표준 HTTP 프로토콜
3. 모든 언어로 구현 가능
4. 테스트 및 디버깅 용이

---

### 7. 표준 프로메테우스 서버를 설치할 때 포함되는 시각화 옵션은 무엇인가?

**답변:**

프로메테우스 서버에 기본적으로 포함된 시각화 옵션은 **내장 웹 UI (Expression Browser)**입니다.

#### 내장 웹 UI (Built-in Web UI)

**접근 방법:**
```
http://<prometheus-server>:9090
```

#### 포함된 기능:

**1. Graph (그래프 탭)**
   - PromQL 쿼리 실행
   - 시계열 데이터를 라인 차트로 시각화
   - 시간 범위 선택 가능
   - 여러 메트릭 동시 표시 가능
   
   ```promql
   # 예시 쿼리
   rate(http_requests_total[5m])
   
   # 결과가 그래프로 표시됨
   ```

**2. Console (콘솔 탭)**
   - 쿼리 결과를 테이블 형태로 표시
   - 현재 시점의 값만 표시 (시계열 아님)
   - 빠른 값 확인에 유용
   
   ```
   쿼리: up
   결과:
   up{job="prometheus", instance="localhost:9090"} 1
   up{job="node", instance="localhost:9100"} 1
   ```

**3. Status 메뉴**
   - **Runtime & Build Information**: 버전, 빌드 정보
   - **Command-Line Flags**: 실행 플래그
   - **Configuration**: 현재 설정 확인
   - **Rules**: 알림 및 레코딩 규칙
   - **Targets**: 스크랩 타겟 상태
   - **Service Discovery**: 디스커버리된 타겟
   - **TSDB Status**: 시계열 DB 통계

**4. Alerts (알림 탭)**
   - 정의된 알림 규칙 목록
   - 현재 firing/pending 알림
   - 알림 상태 및 레이블

#### 내장 UI의 특징:

**장점:**
1. **즉시 사용 가능**
   - 설치 즉시 사용
   - 추가 설정 불필요
   - 별도 소프트웨어 없음

2. **쿼리 개발 및 디버깅**
   - PromQL 쿼리 테스트
   - 자동완성 기능
   - 쿼리 구문 검증

3. **운영 정보 확인**
   - 타겟 health check
   - 설정 검증
   - 성능 메트릭

4. **경량**
   - 최소한의 리소스 사용
   - 빠른 로딩

**단점:**
1. **제한된 시각화 기능**
   - 단순한 라인 차트만 지원
   - 대시보드 기능 없음
   - 다양한 차트 타입 없음 (바 차트, 히트맵 등)

2. **저장 및 공유 불가**
   - 쿼리를 저장할 수 없음
   - 대시보드 생성 불가
   - URL로 쿼리는 공유 가능하지만 제한적

3. **UI/UX 한계**
   - 기본적인 인터페이스
   - 모던한 UI 아님
   - 복잡한 데이터 분석에는 부적합

4. **멀티 프로메테우스 지원 없음**
   - 하나의 프로메테우스만 조회
   - 여러 클러스터 통합 불가

#### 시니어 SRE 관점의 활용:

**내장 UI를 사용하는 경우:**

**1. 쿼리 개발 및 테스트**
```promql
# 새 쿼리 작성 및 검증
histogram_quantile(0.95, 
  rate(http_request_duration_seconds_bucket[5m])
)

# 결과 확인 → Grafana로 이전
```

**2. 빠른 문제 조사**
```
장애 상황:
1. 프로메테우스 UI 접속
2. Status → Targets 확인
3. 문제 있는 타겟 식별
4. 해당 메트릭 쿼리로 조사
```

**3. 설정 검증**
```
배포 후:
- Configuration 탭에서 설정 확인
- Targets 탭에서 스크랩 상태 확인
- Rules 탭에서 알림 규칙 검증
```

**4. TSDB 모니터링**
```
# TSDB Status에서 확인:
- 시계열 카디널리티
- 저장소 사용량
- 청크 수
- 샘플 수

→ 카디널리티 폭발 조기 감지
```

#### 프로덕션 환경 권장 구성:

```
프로메테우스 내장 UI:
- 개발 및 디버깅
- 빠른 쿼리 실행
- 운영 상태 확인
- 문제 조사

+

Grafana:
- 프로덕션 대시보드
- 팀 대시보드
- 알림 시각화
- 비즈니스 메트릭 표시
```

#### 결론:

**표준 프로메테우스 서버에 포함된 시각화는 "내장 웹 UI (Expression Browser)"입니다.**

**특징:**
- 기본적인 그래프 및 테이블 뷰
- 쿼리 개발 및 디버깅에 적합
- 운영 정보 확인에 유용
- 프로덕션 대시보드로는 부족

**실무 권장:**
- **개발/디버깅**: 프로메테우스 내장 UI
- **프로덕션 대시보드**: Grafana
- **두 도구의 조합**이 최선

시니어 SRE는 두 도구의 강점을 이해하고 적절히 활용합니다. 프로메테우스 UI는 "빠른 조사 도구"로, Grafana는 "정식 대시보드 플랫폼"으로 역할을 구분하는 것이 효과적입니다.

---

## 참고 자료

- [Prometheus Architecture](https://prometheus.io/docs/introduction/overview/#architecture)
- [Prometheus Exporters and Integrations](https://prometheus.io/docs/instrumenting/exporters/)
- [Alertmanager Architecture](https://prometheus.io/docs/alerting/latest/alertmanager/)
- [Alertmanager High Availability](https://prometheus.io/docs/alerting/latest/alertmanager/#high-availability)
- [Alertmanager Webhook Configuration](https://prometheus.io/docs/alerting/latest/configuration/#webhook_config)
- [Writing Exporters - Best Practices](https://prometheus.io/docs/instrumenting/writing_exporters/)
- [Prometheus Data Model](https://prometheus.io/docs/concepts/data_model/)
- [PromQL Basics](https://prometheus.io/docs/prometheus/latest/querying/basics/)
- [Prometheus Storage](https://prometheus.io/docs/prometheus/latest/storage/)
- [Prometheus Web UI](https://prometheus.io/docs/visualization/browser/)
- [Alertmanager Clustering](https://github.com/prometheus/alertmanager#high-availability)
